{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "gpuType": "A100",
      "authorship_tag": "ABX9TyPro853vKIb4lIQFI2mkoMY",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/eujin99/gemma2-2b-math/blob/main/gemma2_math.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qfqGhJfjEYzm"
      },
      "outputs": [],
      "source": [
        "!pip install transformers datasets torch"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import load_dataset\n",
        "\n",
        "# GSM8K 데이터셋 로드 (config name 지정)\n",
        "dataset = load_dataset(\"gsm8k\", \"main\", split=\"train\")\n",
        "\n",
        "# 데이터셋 확인\n",
        "print(dataset[0])\n"
      ],
      "metadata": {
        "id": "zTuSeMeSFeL3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# huggingface_hub 토큰 입력\n",
        "\n",
        "from huggingface_hub import notebook_login\n",
        "\n",
        "notebook_login()\n"
      ],
      "metadata": {
        "id": "-4aRLWyrFeOJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 토크나이저, 모델 불러옴\n",
        "\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"google/gemma-2-2b\")\n",
        "model = AutoModelForCausalLM.from_pretrained(\"google/gemma-2-2b\")"
      ],
      "metadata": {
        "id": "CD9dXla1FeP-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "source": [
        "# 데이터셋 토큰화 (입력과 레이블 모두 토큰화)\n",
        "def tokenize_function(examples):\n",
        "    inputs = tokenizer(examples[\"question\"], padding=\"max_length\", truncation=True, max_length=128)\n",
        "    outputs = tokenizer(examples[\"answer\"], padding=\"max_length\", truncation=True, max_length=128)\n",
        "    inputs[\"labels\"] = outputs[\"input_ids\"]  # 레이블 추가\n",
        "    return inputs\n",
        "\n",
        "tokenized_dataset = dataset.map(tokenize_function, batched=True)\n"
      ],
      "cell_type": "code",
      "metadata": {
        "id": "5zGUwT5jIbnm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import Trainer, TrainingArguments\n",
        "\n",
        "# 학습 설정\n",
        "training_args = TrainingArguments(\n",
        "    output_dir='./results',\n",
        "    per_device_train_batch_size=1,\n",
        "    gradient_accumulation_steps=16,  # 그래디언트 누적 스텝을 증가\n",
        "    num_train_epochs=3,\n",
        "    logging_dir='./logs',\n",
        "    save_steps=1000,\n",
        "    save_total_limit=2,\n",
        "    fp16=True  # 혼합 정밀도 학습\n",
        ")\n",
        "\n",
        "\n",
        "\n",
        "# Trainer 설정\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=tokenized_dataset,  # 전처리된 데이터셋\n",
        ")\n",
        "\n",
        "# Fine-tuning 시작\n",
        "trainer.train()\n"
      ],
      "metadata": {
        "id": "KUkwoaBfFeUX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 모델 저장\n",
        "model.save_pretrained(\"./finetuned_gemma2b_math\")\n",
        "tokenizer.save_pretrained(\"./finetuned_gemma2b_math\")\n"
      ],
      "metadata": {
        "id": "7LtiVbT9T9Tp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# huggingface 모델 업로드\n",
        "from huggingface_hub import notebook_login\n",
        "notebook_login()"
      ],
      "metadata": {
        "id": "-zoK_-OkT9Vo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.push_to_hub(\"chloestella/finetuned_gemma2b_math\")\n",
        "tokenizer.push_to_hub(\"chloestella/finetuned_gemma2b_math\")"
      ],
      "metadata": {
        "id": "RrWvJOhgT9Xp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import pipeline\n",
        "\n",
        "# 파이프라인 설정\n",
        "generator = pipeline('text-generation', model='./finetuned_gemma2b_math', tokenizer=tokenizer)\n",
        "\n",
        "# 예시 문제 생성\n",
        "generated_problem = generator(\"Generate a high school algebra problem.\", max_length=100)\n",
        "print(generated_problem[0]['generated_text'])\n"
      ],
      "metadata": {
        "id": "4pF_k6LBT9mC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 질문 및 답변 test\n",
        "user_question = input(\"질문을 입력하세요: \")\n",
        "answer = generator(f\"Provide a step-by-step solution in plain text to solve the equation: {user_question}\", max_length=200)\n",
        "print(\"답변: \", answer[0]['generated_text'])\n"
      ],
      "metadata": {
        "id": "DnCVzEICT9oc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import pipeline\n",
        "\n",
        "# 파이프라인 설정 (CPU로 설정)\n",
        "generator = pipeline('text-generation', model=model, tokenizer=tokenizer, device=\"cpu\")\n",
        "\n",
        "# 문제 생성, 답변 입력 및 채점 함수\n",
        "def generate_and_solve_math_problem():\n",
        "    try:\n",
        "        level = int(input(\"과정을 선택하세요 : 1. 초등 2. 중등 3. 고등\\n\"))\n",
        "\n",
        "        if level == 1:\n",
        "            grade_level = \"elementary\"\n",
        "            topic = \"simple arithmetic\"\n",
        "        elif level == 2:\n",
        "            grade_level = \"middle school\"\n",
        "            topic = \"algebra\"\n",
        "        elif level == 3:\n",
        "            grade_level = \"high school\"\n",
        "            topic = \"calculus\"\n",
        "        else:\n",
        "            print(\"잘못된 입력입니다. 숫자 1, 2, 3 중 하나를 선택하세요.\")\n",
        "            return\n",
        "\n",
        "        # 문제 생성\n",
        "        prompt = f\"Generate a {grade_level} math problem in {topic}. The problem should be simple and require one-step calculation.\"\n",
        "        print(\"문제를 생성중입니다...\\n\")\n",
        "        problem = generator(prompt, max_length=100, num_return_sequences=1)[0]['generated_text']\n",
        "        print(\"문제: \", problem)\n",
        "\n",
        "        # 정답 생성 (사용자에게 공개하지 않음)\n",
        "        answer_prompt = f\"Provide the answer for the problem: {problem}\"\n",
        "        correct_answer = generator(answer_prompt, max_length=50, num_return_sequences=1)[0]['generated_text'].strip()\n",
        "\n",
        "        # 답변 입력\n",
        "        user_answer = input(\"답변을 입력하세요: \")\n",
        "\n",
        "        # 채점\n",
        "        if user_answer.strip() == correct_answer:\n",
        "            print(\"정답입니다!\")\n",
        "        else:\n",
        "            print(f\"오답입니다. 정답은 {correct_answer}입니다.\")\n",
        "\n",
        "        # 풀이 제공\n",
        "        explanation_prompt = f\"Explain the solution step by step for the problem: {problem}.\"\n",
        "        explanation = generator(explanation_prompt, max_length=200)[0]['generated_text']\n",
        "        print(\"풀이: \", explanation)\n",
        "\n",
        "    except ValueError:\n",
        "        print(\"숫자만 입력해주세요.\")\n",
        "\n",
        "# 문제 생성 및 풀이 과정 실행\n",
        "generate_and_solve_math_problem()\n"
      ],
      "metadata": {
        "id": "qYoGFHG6FeYX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Tf20Yba9Febe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "8mlXPls9FeiN"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}